---
title: "Brain in Multiple subjects"
author: "He Junhui"
date: '`r Sys.Date()`'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

+ Modify the data file path
```{r}
# TO DO
pathpre = "path to data file directory"
# pathpre = "G:/Phd/Data/HCPFMRI/WM_contrasts"
pathsuf = "_2bk-0bk.nii"
```


```{r}
library(oro.nifti)
library(neurobase)
library(readxl)
if(!require("devtools")) {install.packages("devtools")}
if(!require("FLGP")) {devtools::install_github("junhuihe2000/FLGP")}
library(FLGP)
if(!require("kernlab")) {install.packages("kernlab")}
library(kernlab)
```

```{r}
if(!file.exists(file.path(pathpre, "tables", "brain"))) {dir.create(file.path(pathpre, "tables", "brain"))}
```


## Experiment

```{r}
num_exps = 2# experiment numbers, 10
m_ratios = c(0.1,0.2,0.5) # the ratio of labeled samples
a = 0.01 # threshold for censored MSE
mset = array(NA, c(4, num_exps, length(m_ratios)))
mse = array(NA, c(4, num_exps, length(m_ratios)))
nll = array(NA, c(4, num_exps, length(m_ratios)))
time = array(NA, c(4, num_exps, length(m_ratios)))
ns = c()
```

```{r}
# hyper parameters
s_ratio = 0.1; r = 3; K_ratio = 0.3
models = list(subsample="kmeans", kernel="lae", gl="cluster-normalized", root=TRUE)
```

```{r}
# act_count = readnii(file.path(pathpre, "activated.nii"))
index.subject = read.csv(file.path(pathpre, "index2bk-0bk.csv"))
```

```{r}
# TODO
nsub = dim(index.subject)[1] # change nsub values and the below loop to submit multiple tasks
# nsub = 5
```

```{r}
time_start = Sys.time()

# TODO
# change c(1:nsub) to c(nsub_1:nsub_2)
for(idx in c(1:nsub)) {
subject = index.subject$subject[idx]
  
cat("\n\n##########################################################\n")  
cat("The subject",subject,"\n")

# read data
data = read.csv(file.path(pathpre, "brain", paste0(subject,"_2bk-0bk.csv")))
# Activation Voxel
I = dim(data)[1]
# act_idx = sapply(c(1:I), function(i) {return(act_count[data[i,1],data[i,2],data[i,3]]>=2)})
# act_idx = (abs(data[,4]) > qnorm(0.7))
act_idx = (abs(data[,4]) > quantile(abs(data[,4]),0.95))
# Process data
data_act = data[act_idx,]
X = as.matrix(data_act[,1:3])
X = apply(X,2,function(x) {return((x-min(x))/(max(x)-min(x)))}) # coordinate transform
y = data_act[,4]

# Run Regression
set.seed(1234)
n = nrow(X)
ns = c(ns, n)
s = round(n*s_ratio); K = round(s*K_ratio)

for(i in c(1:length(m_ratios))) {

for(num_exp in c(1:num_exps)) {
  

cat("\n\n##########################################################\n")  
cat(paste0("When m_ratio = ",m_ratios[i],", the ",num_exp, "-th experiment:\n\n"))
  
# regression
m = round(n*m_ratios[i])
train.index = sample.int(n, m)
test.index = c(1:n)[-train.index]
X.train = X[train.index,]; X.test = X[test.index,]
y.train = y[train.index]; y.test = y[test.index]


# radial basis kernel function
t1 = Sys.time()
var = 3e-2
rbf.hcp = gausspr(x=X.train, y=y.train, scaled=FALSE, var=var, variance.model=TRUE)
train_pred.hcp = predict(rbf.hcp, X.train)
test_pred.hcp = predict(rbf.hcp, X.test)
t2 = Sys.time()
mset.rbf = mean((y.train-train_pred.hcp)^2)
mset[1,num_exp,i] = mset.rbf
idx.rbf = order((y.test-test_pred.hcp)^2)[round((n-m)*a):round((n-m)*(1-a))]
mse.rbf.win = mean(((y.test-test_pred.hcp)^2)[idx.rbf])
# mse.rbf.win = mean(sort((y.test-test_pred.hcp)^2)[round((n-m)*a):round((n-m)*(1-a))])
mse[1,num_exp,i] = mse.rbf.win

mean = cbind(test_pred.hcp[idx.rbf])
# cov = cbind(predict(rbf.hcp, X.test, type="variance")[idx.rbf])
kernel = rbf.hcp@kernelf
C11 = kernelMatrix(kernel, X.train) + diag(rep(var,m))
C21 = kernelMatrix(kernel, X.test, X.train)
C22 = rep(1+var,n-m)
cov = cbind((C22 - rowSums((C21%*%solve(C11))*C21))[idx.rbf])
nll.rbf = negative_log_likelihood(mean, cov, y.test[idx.rbf], "regression")
nll[1,num_exp,i] = nll.rbf

time[1,num_exp,i] = as.numeric(t2-t1, units="hours")*3600

# Nystrom extension
t1 = Sys.time()
res_nystrom.hcp = fit_nystrom_regression_gp_rcpp(X.train, y.train, X.test, s, K, sigma = 5e-3)
t2 = Sys.time()
y_nystrom.hcp = res_nystrom.hcp$Y_pred
train_pred_nystrom.hcp = y_nystrom.hcp$train
test_pred_nystrom.hcp = y_nystrom.hcp$test
mset.nystrom = mean((y.train-train_pred_nystrom.hcp)^2)
mset[2,num_exp,i] = mset.nystrom
idx.nystrom = order((y.test-test_pred_nystrom.hcp)^2)[round((n-m)*a):round((n-m)*(1-a))]
mse.nystrom.win = mean(((y.test-test_pred_nystrom.hcp)^2)[idx.nystrom])
# mse.nystrom.win = mean(sort((y.test-test_pred_nystrom.hcp)^2)[round((n-m)*a):round((n-m)*(1-a))])
mse[2,num_exp,i] = mse.nystrom.win

mean = cbind(res_nystrom.hcp$posterior$mean[idx.nystrom])
cov = cbind(res_nystrom.hcp$posterior$cov[idx.nystrom])
nll.nystrom = negative_log_likelihood(mean, cov, y.test[idx.nystrom], "regression")
nll[2,num_exp,i] = nll.nystrom

time[2,num_exp,i] = as.numeric(t2-t1, units="hours")*3600

# SKFLGP
models$subsample = "kmeans"; models$gl = "cluster-normalized"
t1 = Sys.time()
res_skflag.hcp = fit_se_regression_gp_rcpp(X.train, y.train, X.test, s, r, K, models = models, sigma = 5e-3)
t2 = Sys.time()
y_skflag.hcp = res_skflag.hcp$Y_pred
train_pred_skflag.hcp = y_skflag.hcp$train
test_pred_skflag.hcp = y_skflag.hcp$test
mset.skflag = mean((y.train-train_pred_skflag.hcp)^2)
mset[3,num_exp,i] = mset.skflag
idx.skflag = order((y.test-test_pred_skflag.hcp)^2)[round((n-m)*a):round((n-m)*(1-a))]
mse.skflag.win = mean(((y.test-test_pred_skflag.hcp)^2)[idx.skflag])
# mse.lkflag.win = mean(sort((y.test-test_pred_lkflag.hcp)^2)[round((n-m)*a):round((n-m)*(1-a))])
mse[3,num_exp,i] = mse.skflag.win

mean = cbind(res_skflag.hcp$posterior$mean[idx.skflag])
cov = cbind(res_skflag.hcp$posterior$cov[idx.skflag])
nll.skflag = negative_log_likelihood(mean, cov, y.test[idx.skflag], "regression")
nll[3,num_exp,i] = nll.skflag

time[3,num_exp,i] = as.numeric(t2-t1, units="hours")*3600

# LKFLGP
models$subsample = "kmeans"; models$gl = "cluster-normalized"
t1 = Sys.time()
res_lkflag.hcp = fit_lae_regression_gp_rcpp(X.train, y.train, X.test, s, r, K, models = models, sigma = 5e-3)
t2 = Sys.time()
y_lkflag.hcp = res_lkflag.hcp$Y_pred
train_pred_lkflag.hcp = y_lkflag.hcp$train
test_pred_lkflag.hcp = y_lkflag.hcp$test
mset.lkflag = mean((y.train-train_pred_lkflag.hcp)^2)
mset[4,num_exp,i] = mset.lkflag
idx.lkflag = order((y.test-test_pred_lkflag.hcp)^2)[round((n-m)*a):round((n-m)*(1-a))]
mse.lkflag.win = mean(((y.test-test_pred_lkflag.hcp)^2)[idx.lkflag])
# mse.lkflag.win = mean(sort((y.test-test_pred_lkflag.hcp)^2)[round((n-m)*a):round((n-m)*(1-a))])
mse[4,num_exp,i] = mse.lkflag.win

mean = cbind(res_lkflag.hcp$posterior$mean[idx.lkflag])
cov = cbind(res_lkflag.hcp$posterior$cov[idx.lkflag])
nll.lkflag = negative_log_likelihood(mean, cov, y.test[idx.lkflag], "regression")
nll[4,num_exp,i] = nll.lkflag

time[4,num_exp,i] = as.numeric(t2-t1, units="hours")*3600

gc()

}
}

save(list = c("mset", "mse", "nll", "time"), file = file.path(pathpre, "tables/brain", paste0(subject,".Rdata")))

## manipulate experiment results
cat("The number of total samples is n = ",n,":\n", sep = "")
res_table = as.data.frame(matrix(0,nrow=4,ncol=length(m_ratios)*4))
colnames(res_table) = rep(c("training mse", "test mse", "nll", "time"), length(m_ratios))
rownames(res_table) = c("RBF GP", "Nystrom", "SKFLGP", "LKFLGP")

mydigits = 3

for(i in c(1:length(m_ratios))) {
  res_table[,(4*i-3)] = round(rowMeans(mset[,,i]), digits = mydigits)
  res_table[,(4*i-2)] = round(rowMeans(mse[,,i]), digits = mydigits)
  res_table[,(4*i-1)] = round(rowMeans(nll[,,i]), digits = mydigits)
  res_table[,(4*i)] = round(rowMeans(time[,,i]), digits = mydigits)
}

print(res_table)
}
save(ns, file = file.path(pathpre, "tables/brain", "ns.Rdata"))
time_end = Sys.time()
```

```{r}
print(time_end-time_start)
```
