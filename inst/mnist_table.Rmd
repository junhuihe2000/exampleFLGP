---
title: "MNIST table"
author: "He Junhui"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(devtools)
library(kernlab)
library(FLGP)
library(microbenchmark)
library(bigmemory)
load_all()
```

```{r}
#######################################################
# The second example
# MNIST examples
# 70000 * 28 * 28
setwd("G:/Rtext/Rstudio/exampleFLGP/inst/")
set.seed(1234)
```

```{r}
# read mnist samples
inputpath = "G:/Phd/Data/MNIST/augmnist/"
# xbm.mnist = read.big.matrix(paste0(inputpath, "images.csv"), has.row.names =  TRUE, type = "double", skip = 1)
```

```{r}
# DO PCA
# p = 100
# x.pca.mnist = prcomp(x=xbm.mnist[,], rank. = p)
# write.csv(x=x.pca.mnist$x, file = paste0(inputpath, "images_pca.csv"))
```

```{r}
xbmpca.mnist = read.big.matrix(paste0(inputpath, "images_pca.csv"), has.row.names =  TRUE, type = "double", skip = 1)
y.mnist = read.big.matrix(paste0(inputpath, "labels.csv"), has.row.names = TRUE,
                          type = "double", skip = 1)
```

## Experiment
```{r}
n = 700000
num_exps = 5 # experiment numbers
m = 200 # number of labeled samples
errors = array(NA, c(9, num_exps))
times = array(NA, c(9, num_exps))
nlls = array(NA, c(8, num_exps))
```

```{r}
# hyper parameters
s = 1000; r = 3; K = 100
models = list(subsample="minibatchkmeans", kernel="lae", gl="cluster-normalized", root=TRUE)
```

```{r, include=FALSE}
time_start = Sys.time()


for(num_exp in c(1:num_exps)) {
  

cat("\n\n##########################################################\n")  
cat(paste0("When m = ",m,", the ",num_exp, "-th experiment:\n\n"))
  
# classification
train.index = sample.int(n, m)
test.index = c(1:n)[-train.index]
train.data = xbmpca.mnist[train.index,]; test.data = xbmpca.mnist[test.index,]
y_train.mnist = y.mnist[train.index]; y_new.mnist = y.mnist[test.index]

if(TRUE) {
# radial basis kernel function
t1 = Sys.time()
rbf.model = train_multi_classification(train.data, y_train.mnist)
rbf.mnist = predict_multi_classification(test.data, rbf.model)
y_rbf.mnist = rbf.mnist$pred
t2 = Sys.time()
err.rbf.mnist = mean(y_new.mnist!=y_rbf.mnist)
print(err.rbf.mnist)

mean = rbf.mnist$posterior$mean
cov = rbf.mnist$posterior$cov
nll_rbf.mnist = negative_log_likelihood(mean, cov, y_new.mnist, "multinomial")

errors[1,num_exp] = err.rbf.mnist
times[1,num_exp] = as.numeric(t2-t1, units="hours")*3600
nlls[1,num_exp] = nll_rbf.mnist
}


if(FALSE) {
# ksvm
t1 = Sys.time()
ksvm.mnist = ksvm(x=train.data, y=as.factor(y_train.mnist), type="C-svc", scaled=FALSE)
pred_label.ksvm.mnist = predict(ksvm.mnist, test.data)
t2 = Sys.time()
err.ksvm.mnist = mean(y_new.mnist!=pred_label.ksvm.mnist)
print(err.ksvm.mnist)

errors[2,num_exp] = err.ksvm.mnist
times[2,num_exp] = as.numeric(t2-t1, units="hours")*3600
}

# FLGP

# GLGP
if(FALSE) {
t1 = Sys.time()
bwd = exp(seq(log(0.05),log(10),length.out=20))
gl.mnist = fit_gl_logit_mult_gp_rcpp(train.data, y_train.mnist, test.data, K,
                                         sparse = FALSE, a2s = bwd)
t2 = Sys.time()
y_gl.mnist = gl.mnist$Y_pred
err_gl.mnist = mean(y_new.mnist!=y_gl.mnist$test)
print(err_gl.mnist)

mean = gl.mnist$posterior$mean
cov = gl.mnist$posterior$cov
nll_gl.mnist = negative_log_likelihood(mean, cov, y_new.mnist, "multinomial")

errors[3,num_exp] = err_gl.mnist
times[3,num_exp] = as.numeric(t2-t1, units="hours")*3600
nlls[2,num_exp] = nll_gl.mnist
}



if(FALSE){
# sparseGLGP
t1 = Sys.time()
bwd = exp(seq(log(0.5),log(10),length.out=20))
glsp.mnist = fit_gl_logit_mult_gp_rcpp(train.data, y_train.mnist, test.data, K, threshold = 0.002, sparse = TRUE, a2s = bwd)
t2 = Sys.time()
y_glsp.mnist = glsp.mnist$Y_pred
err_glsp.mnist = mean(y_new.mnist!=y_glsp.mnist$test)
print(err_glsp.mnist)

mean = glsp.mnist$posterior$mean
cov = glsp.mnist$posterior$cov
nll_glsp.mnist = negative_log_likelihood(mean, cov, y_new.mnist, "multinomial")

errors[4,num_exp] = err_glsp.mnist
times[4,num_exp] = as.numeric(t2-t1, units="hours")*3600
nlls[3,num_exp] = nll_glsp.mnist
}

if(TRUE) {
# Nystrom extension
t1 = Sys.time()
bwd = exp(seq(log(0.1),log(10),length.out=20))
nystrom.mnist = fit_nystrom_logit_mult_gp_rcpp(train.data, y_train.mnist, test.data, s, K, a2s = bwd, subsample = "minibatchkmeans")
t2 = Sys.time()
y_nystrom.mnist = nystrom.mnist$Y_pred
err_nystrom.mnist = mean(y_new.mnist!=y_nystrom.mnist$test)
print(err_nystrom.mnist)

mean = nystrom.mnist$posterior$mean
cov = nystrom.mnist$posterior$cov
nll_nystrom.mnist = negative_log_likelihood(mean, cov, y_new.mnist, "multinomial")

errors[5,num_exp] = err_nystrom.mnist
times[5,num_exp] = as.numeric(t2-t1, units="hours")*3600
nlls[4,num_exp] = nll_nystrom.mnist
}

if(TRUE) {
# SRFLGP
models$subsample = "random"; models$gl = "normalized"
t1 = Sys.time()
bwd = exp(seq(log(0.1),log(10),length.out=20))
srflag.mnist = fit_se_logit_mult_gp_rcpp(train.data, y_train.mnist, test.data, s, r, K, models = models, a2s = bwd)
t2 = Sys.time()
y_srflag.mnist = srflag.mnist$Y_pred
err_srflag.mnist = mean(y_new.mnist!=y_srflag.mnist$test)
print(err_srflag.mnist)

mean = srflag.mnist$posterior$mean
cov = srflag.mnist$posterior$cov
nll_srflag.mnist = negative_log_likelihood(mean, cov, y_new.mnist, "multinomial")

errors[6,num_exp] = err_srflag.mnist
times[6,num_exp] = as.numeric(t2-t1, units="hours")*3600
nlls[5,num_exp] = nll_srflag.mnist

# SKFLGP
models$subsample = "minibatchkmeans"; models$gl = "cluster-normalized"
t1 = Sys.time()
bwd = exp(seq(log(0.1),log(10),length.out=20))
skflag.mnist = fit_se_logit_mult_gp_rcpp(train.data, y_train.mnist, test.data, s, r, K, models = models, a2s = bwd)
t2 = Sys.time()
y_skflag.mnist = skflag.mnist$Y_pred
err_skflag.mnist = mean(y_new.mnist!=y_skflag.mnist$test)
print(err_skflag.mnist)

mean = skflag.mnist$posterior$mean
cov = skflag.mnist$posterior$cov
nll_skflag.mnist = negative_log_likelihood(mean, cov, y_new.mnist, "multinomial")

errors[7,num_exp] = err_skflag.mnist
times[7,num_exp] = as.numeric(t2-t1, units="hours")*3600
nlls[6,num_exp] = nll_skflag.mnist
}

if(TRUE) {
# LRFLGP
models$subsample = "random"; models$gl = "normalized"
t1 = Sys.time()
lrflag.mnist = fit_lae_logit_mult_gp_rcpp(train.data, y_train.mnist, test.data, s, r, K, models = models)
t2 = Sys.time()
y_lrflag.mnist = lrflag.mnist$Y_pred
err_lrflag.mnist = mean(y_new.mnist!=y_lrflag.mnist$test)
print(err_lrflag.mnist)

mean = lrflag.mnist$posterior$mean
cov = lrflag.mnist$posterior$cov
nll_lrflag.mnist = negative_log_likelihood(mean, cov, y_new.mnist, "multinomial")

errors[8,num_exp] = err_lrflag.mnist
times[8,num_exp] = as.numeric(t2-t1, units="hours")*3600
nlls[7,num_exp] = nll_lrflag.mnist
}


# LKFLGP
models$subsample = "minibatchkmeans"; models$gl = "cluster-normalized"
t1 = Sys.time()
lkflag.mnist = fit_lae_logit_mult_gp_rcpp(train.data, y_train.mnist, test.data, s, r, K, models = models)
t2 = Sys.time()
y_lkflag.mnist = lkflag.mnist$Y_pred
err_lkflag.mnist = mean(y_new.mnist!=y_lkflag.mnist$test)
print(err_lkflag.mnist)

mean = lkflag.mnist$posterior$mean
cov = lkflag.mnist$posterior$cov
nll_lkflag.mnist = negative_log_likelihood(mean, cov, y_new.mnist, "multinomial")

errors[9,num_exp] = err_lkflag.mnist
times[9,num_exp] = as.numeric(t2-t1, units="hours")*3600
nlls[8,num_exp] = nll_lkflag.mnist

gc()

}

time_end = Sys.time()
time_diff = time_end - time_start
```

```{r}
print(time_diff)
# Time difference of 36.04668 mins
# Time difference of 2.251741 hours
# Time difference of 7.510066 hours
```


```{r}
save(list = c("errors", "nlls", "times"), file = paste0("data/mnist_data_",n,".Rdata"))
```


## manipulate results

```{r}
cat("The number of total samples is n = ",n,":\n", sep = "")
errors_table = as.data.frame(rep(0,9))
times_table = as.data.frame(round(rowMeans(times), digits = 1))
nlls_table = as.data.frame(rep(0,8))
rownames(errors_table) = c("EGP", "KSVM", "GLGP", "sparseGLGP", "Nystrom extension", 
                        "SRFLGP", "SKFLGP", "LRFLGP", "LKFLGP")
rownames(times_table) = c("EGP", "KSVM", "GLGP", "sparseGLGP", "Nystrom extension", 
                        "SRFLGP", "SKFLGP", "LRFLGP", "LKFLGP")
rownames(nlls_table) = c("EGP", "GLGP", "sparseGLGP", "Nystrom extension", 
                        "SRFLGP", "SKFLGP", "LRFLGP", "LKFLGP")
colnames(errors_table) = paste0("n = ",n)
colnames(nlls_table) = paste0("n = ",n)
colnames(times_table) = paste0("n = ",n)


errors_mean = round(rowMeans(errors)*100, digits = 1)
errors_sd = round(apply(errors*100, 1, sd), digits = 1)
for(i in 1:9) {
  errors_table[i,1] = paste0(errors_mean[i],"(",errors_sd[i],")")
}

nlls_mean = round(rowMeans(nlls), digits = 1)
nlls_sd = round(apply(nlls, 1, sd), digits = 2)
for(i in 1:8) {
  nlls_table[i,1] = paste0(nlls_mean[i],"(",nlls_sd[i],")")
}
```


```{r}
write.csv(errors_table, paste0("tables/mnist_revision/errors_",n,".csv"))
print(errors_table)
```

```{r}
write.csv(nlls_table, paste0("tables/mnist_revision/nlls_",n,".csv"))
print(nlls_table)
```

```{r}
write.csv(times_table, paste0("tables/mnist_revision/times_",n,".csv"))
print(times_table)
```
