---
title: "MNIST Sensitivity Analysis"
author: "He Junhui"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(kernlab)
library(FLAG)
library(microbenchmark)
library(bigmemory)
```

```{r}
#######################################################
# The second example
# MNIST examples
# 70000 * 28 * 28

set.seed(1234)
```

```{r}
# read mnist samples
inputpath = "G:/Phd/Data/MNIST/mnist/"
# xbm.mnist = read.big.matrix(paste0(inputpath, "images.csv"), has.row.names =  TRUE, type = "double", skip = 1)
```

```{r}
# DO PCA
# p = 100
# x.pca.mnist = prcomp(x=xbm.mnist[,], rank. = p)
# write.csv(x=x.pca.mnist$x, file = paste0(inputpath, "images_pca.csv"))
```

```{r}
xbmpca.mnist = read.big.matrix(paste0(inputpath, "images_pca.csv"), has.row.names =  TRUE, type = "double", skip = 1)
y.mnist = read.big.matrix(paste0(inputpath, "labels.csv"), has.row.names = TRUE,
                          type = "double", skip = 1)
```

## Experiment


```{r}
n = dim(xbmpca.mnist)[1]
ns_used = c(70000)
num_exps = 10 # experiment numbers
ms = c(100,200) # number of labeled samples
# res_list = lapply(c(1:(length(ms)*2)), function(i) {return(matrix(NA,nrow=4,ncol=num_exps))})
res_lists = list()
```

```{r}
# hyper parameters
s = 1000; r = 3; K = 300
models = list(subsample="kmeans", kernel="lae", gl="cluster-normalized", root=TRUE)
```

```{r}
set.seed(1234)
```

```{r, include=FALSE}
time_start = Sys.time()

for(j in c(1:length(ns_used))) {
n_used = ns_used[j]
res_list = lapply(c(1:(length(ms)*2)), function(i) {return(matrix(NA,nrow=4,ncol=num_exps))})

for(i in c(1:length(ms))) {

for(num_exp in c(1:num_exps)) {
  

cat("\n\n##########################################################\n")  
cat(paste0("When n = ",n_used,", m = ",ms[i],", the ",num_exp, "-th experiment:\n\n"))
  
# classification
m = ms[i]
train.index = sample.int(n, m)
test.index = sample(c(1:n)[-train.index],n_used-m)
train.data = xbmpca.mnist[train.index,]; test.data = xbmpca.mnist[test.index,]
y_train.mnist = y.mnist[train.index]; y_new.mnist = y.mnist[test.index]


# FLAG

# SRFLAG
models$subsample = "random"; models$gl = "normalized"
t1 = Sys.time()
y_srflag.mnist = fit_se_logit_mult_gp_rcpp(train.data, y_train.mnist, test.data, s, r, K, models = models)
t2 = Sys.time()
err_srflag.mnist = sum((y_new.mnist!=y_srflag.mnist$test)^2)/(n_used-m)

res_list[[2*i-1]][1,num_exp] = err_srflag.mnist
res_list[[2*i]][1,num_exp] = as.numeric(t2-t1, units="hours")*3600

# SKFLAG
models$subsample = "kmeans"; models$gl = "cluster-normalized"
t1 = Sys.time()
y_skflag.mnist = fit_se_logit_mult_gp_rcpp(train.data, y_train.mnist, test.data, s, r, K, models = models)
t2 = Sys.time()
err_skflag.mnist = sum((y_new.mnist!=y_skflag.mnist$test)^2)/(n_used-m)

res_list[[2*i-1]][2,num_exp] = err_skflag.mnist
res_list[[2*i]][2,num_exp] = as.numeric(t2-t1, units="hours")*3600


# LRFLAG
models$subsample = "random"; models$gl = "normalized"
t1 = Sys.time()
y_lrflag.mnist = fit_lae_logit_mult_gp_rcpp(train.data, y_train.mnist, test.data, s, r, K, models = models)
t2 = Sys.time()
err_lrflag.mnist = sum((y_new.mnist!=y_lrflag.mnist$test)^2)/(n_used-m)

res_list[[2*i-1]][3,num_exp] = err_lrflag.mnist
res_list[[2*i]][3,num_exp] = as.numeric(t2-t1, units="hours")*3600


# LKFLAG
models$subsample = "kmeans"; models$gl = "cluster-normalized"
t1 = Sys.time()
y_lkflag.mnist = fit_lae_logit_mult_gp_rcpp(train.data, y_train.mnist, test.data, s, r, K, models = models)
t2 = Sys.time()
err_lkflag.mnist = sum((y_new.mnist!=y_lkflag.mnist$test)^2)/(n_used-m)

res_list[[2*i-1]][4,num_exp] = err_lkflag.mnist
res_list[[2*i]][4,num_exp] = as.numeric(t2-t1, units="hours")*3600

gc()

}
  
}

res_lists[[j]] = res_list
}

time_end = Sys.time()
time_diff = time_end - time_start
```

```{r}
print(time_diff)
# Time difference of 36.04668 mins
```


## manipulate results
```{r}
cat("The number of total samples is n_used = ",n_used,":\n", sep = "")
res_tables = as.data.frame(matrix(0,nrow=4,ncol=length(ms)*2*length(ns_used)))
colnames(res_tables) = rep(c("error rates", "time"), length(ms)*length(ns_used))
rownames(res_tables) = c("SRFLAG", "SKFLAG", "LRFLAG", "LKFLAG")
for(k in c(1:length(ns_used))) {
res_list = res_lists[[k]]
res_table = as.data.frame(matrix(0,nrow=4,ncol=length(ms)*2))
colnames(res_table) = rep(c("error rates", "time"), length(ms))
rownames(res_table) = c("SRFLAG", "SKFLAG", "LRFLAG", "LKFLAG")
mydigits = 1
for(i in c(1:length(ms))) {
  # time
  res_table[,(2*i)] = round(rowMeans(res_list[[(2*i)]]), digits = mydigits)
  
  error_mean = round(rowMeans(res_list[[(2*i-1)]])*100, digits = mydigits)
  error_std = round(apply(res_list[[(2*i-1)]]*100, 1, sd), digits = mydigits)
  for(j in c(1:4)) {
    res_table[j,(2*i-1)] = paste0(error_mean[j],"(",error_std[j],")")
  }
}
res_tables[,(4*k-3):(4*k)] = res_table
}

```

```{r}
write.csv(res_tables, paste0("tables/mnist/","s",s,"r",r,"K",K,".csv"))
print(res_tables)
```

